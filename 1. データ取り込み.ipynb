{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcf42a47-3287-4b24-9dfb-4b528d41e9fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# データ取り込み\n",
    "\n",
    "このノートブックはETL処理における **E(Extract:抽出)** に該当します。Pythonを用いてインターネットからCSVファイルを取得します。\n",
    "\n",
    "こちらは、[Azure Databricks ジョブを使用して最初のワークフローを作成する](https://learn.microsoft.com/ja-jp/azure/databricks/jobs/jobs-quickstart)のサンプルノートブックをベースとしています。\n",
    "\n",
    "まず、このノートブックを[ノートブック用のサーバレスコンピューティング](https://learn.microsoft.com/ja-jp/azure/databricks/compute/serverless/notebooks)で実行し、その後で[ジョブ用のサーバレスコンピューティング](https://learn.microsoft.com/ja-jp/azure/databricks/jobs/run-serverless-jobs)を用いてジョブとして実行します。\n",
    "\n",
    "ノートブック右上の**接続**から**サーバレス**を選択してください。\n",
    "\n",
    "![](https://sajpstorage.blob.core.windows.net/yayoi/202412_handson/serverless_notebook.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88f88022-de6a-4148-abe0-87b2580b35d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Unity Catalog\n",
    "\n",
    "Databricksの資産(テーブルやファイルなど)はすべて[Unity Catalog](https://learn.microsoft.com/ja-jp/azure/databricks/data-governance/unity-catalog/)によって管理されます。データエンジニアリングを行う際には、対象のデータがUnity Catalogのどこに存在しているのかを理解することはとても重要です。\n",
    "\n",
    "Unity Catalogを用いることで、以下の機能でDatabricks上の資産に対するガバナンスを強化することができます。\n",
    "\n",
    "- **データアクセス制御**\n",
    "  - 一度定義するだけで、全てのワークスペース、全ての言語、全てのユースケースに対してセキュリティを適用\n",
    "- **監査機能**\n",
    "  - ガバナンスユースケースに対応するために、全てのクエリーに対するきめ細かい監査を実現\n",
    "- **データリネージ**\n",
    "  - テーブル、カラムに対するデータリネージの自動収集\n",
    "- **データ探索**\n",
    "  - お使いのレイクハウスにおいてデータ利用者が信頼できるデータを検索するためのインタフェースを提供\n",
    "- **属性ベースのアクセス制御**\n",
    "  - 行列レベルのネイティブなセキュリティ、タグによるポリシー適用\n",
    "\n",
    "### 3レベルの名前空間\n",
    "\n",
    "Unity Catalogはデータを整理するために3レベルの名前空間、カタログ、スキーマ(データベースとも呼ばれます)、テーブルとビューを提供します。テーブルを参照するには以下の文法を使用します。\n",
    "\n",
    ">`<catalog>.<schema>.<table>`\n",
    "\n",
    "![3_level_namespace.png](./img/3_level_namespace.png \"3_level_namespace.png\")\n",
    "\n",
    "ファイルは[ボリューム](https://learn.microsoft.com/ja-jp/azure/databricks/volumes/)という場所に格納されます。ボリュームはテーブルと同様`カタログ.スキーマ(データベース).ボリューム`という三階層で管理されます。また、ボリュームに格納されているファイルには[パス](https://learn.microsoft.com/ja-jp/azure/databricks/data-governance/unity-catalog/paths)を指定してアクセスすることができます。データエンジニアリングにおいては、ファイルの取り扱いは不可欠ですので、パスの考え方に慣れるようにしましょう。\n",
    "\n",
    "`<catalog_name>.<schema_name>.<volume_name>`で管理されているボリュームには、PythonやSQLから`/Volumes/<catalog_name>/<schema_name>/<volume_name>/<path_to_file>`というパスでアクセスすることができます。\n",
    "\n",
    "まず、今回のハンズオンで使用するカタログ、スキーマ、ボリュームを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37164a6f-da7c-4d27-a21c-fd8dd8fb396f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6daa710-d5f2-4a01-b30c-9a657f46cbef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## カタログの指定\n",
    "\n",
    "使用するカタログやスキーマ(データベース)にアクセスするには明示的に指定する必要があります。`USE CATALOG`文を用いて、上で表示される作成済みのカタログを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4391904f-080f-4f7c-bc07-6b309f014908",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 使用するカタログを指定\n",
    "spark.sql(f\"USE CATALOG {CATALOG_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c2deb5-fee1-49ae-904c-4b8437ae3a78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## スキーマ(データベース)の作成\n",
    "\n",
    "皆様のユーザー名(メールアドレス)をベースとしたスキーマを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b64fb710-1db1-49cb-9f21-541f22b6c6b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 皆様のユーザー名からスキーマ名を生成し、スキーマを作成\n",
    "DROP TEMPORARY VARIABLE IF EXISTS database_name;\n",
    "DECLARE database_name = concat(\"schema_\", regexp_replace(session_user(), '[\\.@-]', '_'));\n",
    "CREATE DATABASE IF NOT EXISTS IDENTIFIER(database_name);\n",
    "SELECT database_name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6358ab66-0a7d-4f8f-8f2d-153d4cd597fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# スキーマ名(データベース)\n",
    "SCHEMA_NAME = _sqldf.first()[\"database_name\"]\n",
    "print(f\"ハンズオンで使用するスキーマは {SCHEMA_NAME} です。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b917a20-78a4-4aac-8a1a-4196cf2aaf0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ボリュームの作成\n",
    "\n",
    "カタログとスキーマ(データベース)の準備ができたので、ボリュームを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cde45bdc-9c93-4a40-8e94-794fcefc96cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}.{VOLUME_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "180b959f-d0b8-4a41-9f8c-b42ad2a6e568",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "以下のコマンドを実行して表示されるリンクをクリックしてボリュームを確認します。リンク先の画面は[カタログエクスプローラ](https://learn.microsoft.com/ja-jp/azure/databricks/catalog-explorer/)と呼ばれるものであり、Unity Catalogで管理されている資産をGUIから確認、操作することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e987d18-3336-43f7-aa99-b0ba10e6c72d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "displayHTML(f\"<a href='/explore/data/volumes/{CATALOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}' target='_blank'>作成したボリュームを表示</a>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "701341d8-c3b3-41d4-ab0e-d0782fea1d8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## データの取り込み\n",
    "\n",
    "[requests](https://pypi.org/project/requests/)を用いてインターネットからCSVファイルを取得し、[dbutils.fs.put](https://learn.microsoft.com/ja-jp/azure/databricks/dev-tools/databricks-utils#dbutils-fs-cp)を用いてファイルをボリュームにコピーします。ここでは[ニューヨークの公開データ](https://health.data.ny.gov/)を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8f39d4b-43ab-4d2e-b31c-93e1ce0508be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# データを取得して保存する\n",
    "import requests\n",
    "\n",
    "# CSVファイルを取得\n",
    "response = requests.get('https://health.data.ny.gov/api/views/jxy9-yhdk/rows.csv')\n",
    "csvfile = response.content.decode('utf-8')\n",
    "\n",
    "# CSVファイルをボリュームに保存\n",
    "dbutils.fs.put(f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}/babynames.csv\", csvfile, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87e179f8-a0a1-4913-b0f8-ee8ed18c51b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "もう一度カタログエクスプローラにアクセスして、ボリュームにファイルが保存されていることを確認しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f6a59b7-2d2f-413f-939b-85cbeef424c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## データの確認\n",
    "\n",
    "以下のコマンドは、SparkのPython APIである[PySpark](https://learn.microsoft.com/ja-jp/azure/databricks/pyspark/basics)を用いてCSVを読み込み内容を表示します。これが今回のハンズオンで使用する生データとなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7305fa60-ebf1-4c9b-8609-ba64ee114b14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CSVファイルを読み込む\n",
    "babynames = (\n",
    "    spark.read.format(\"csv\") # CSVフォーマット\n",
    "    .option(\"header\", \"true\") # ヘッダーあり\n",
    "    .option(\"inferSchema\", \"true\") # スキーマの推定\n",
    "    .load(f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}/babynames.csv\") # ファイルパスを指定\n",
    ")\n",
    "display(babynames)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4599680339872487,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1. データ取り込み",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
